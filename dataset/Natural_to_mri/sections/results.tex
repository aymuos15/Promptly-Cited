\section{Results}
Tables~\ref{tab:adni_results} and~\ref{tab:brain_age_results}  summarize the performance of different models for  AD and brain age  prediction, respectively. We observed that the 2D-Slice-CNN was better at predicting brain age when using the same hyperparameters as~\cite{gupta2021improved}. However, our 3D-CNN results are better than 2D-Slice-CNN (Table~\ref{tab:brain_age_results}), and the reported numbers in~\cite{gupta2021improved} (3.02 vs.\ 2.792 MAE) due to switching from PyTorch's default initialization to explicitly using He initialization~\cite{he2015delving} and using \sgd\ optimizer. Similarly, 3D-CNN outperforms the 2D-Slice-CNN for AD prediction (88.40 vs.\ 87.53 accuracy). We hypothesized that this might be due to 2D-Slice-CNN combining slice embeddings with permutation invariant operation and consequently losing information about the position of the slice in MRI. We, thus, incorporate positional encodings in the 2D-Slice model.

\subsection{Effect of Position Encodings on the 2D-Slice-CNN.}
Introducing position encodings improved 2D-Slice models for AD prediction in some cases. When using 2D-ResNet-18 encoder (not pretrained), we see improvements in AD prediction when slices along \axisone\ and \axisthree\ directions are used. However, in other cases, the performance on the AD prediction task did not improve when incorporating position encodings.  For brain age prediction, the model performance stayed identical (ResNet Encoders) or deteriorated (5-layer CNN) when using position encodings.
Brain MRIs are usually aligned to a standard template, so the position of specific patterns can provide extra information. However, it may also make the model more sensitive to minor changes in the alignment template and cause overfitting. This could be a potential reason why the performance did not improve on incorporating position encoding.   Here,  we incorporate position encodings in the higher layers. Thus the model may not be able to exploit the spatial information best. Placement of position encodings is crucial~\cite{chen2021demystifying} and left for future work. Overall, position encodings helped in limited cases, and the gains may be task and model dependent.



\subsection{Can Encoders Pretrained on ImageNet improve 3D Deep Neuroimaging?}
We answer this in the affirmative. We finetune 2D-Slice models with ResNet encoders initialized with ImageNet-1K pretrained weights. Initializing with pretrained weights consistently outperforms random initialization (i.e., training from scratch) in all cases (See Tables \ref{tab:adni_results} and~\ref{tab:brain_age_results}). These results validate our hypothesis that a) models trained on natural images (2D) can be helpful for neuroimaging tasks and b) 2D-Slice-CNNs can be used to transfer 2D models to 3D data directly.

Our main goal with these experiments is to demonstrate improvement in performance due to natural image pretraining. Nevertheless, another interesting outcome is that 2D-Slice models with pretrained encoders are the best for both tasks, outperforming the 3D-CNN as well. For the AD  task, we observe that 3D-CNN has a balanced accuracy of 88.40. In contrast, models with pretrained ResNet-18 encoder model have a balanced accuracy of 88.6 when using slices along the axial direction (both with and without position encodings). Similarly, the best MAE with the pretrained model for brain age prediction is 2.715 compared to 2.792 MAE with 3D-CNN. Finally, We also evaluated if increasing the size of the pretrained encoder may lead to more gain by employing ResNet-50 as the encoder for brain age prediction.
We did not see significant improvements over ResNet-18, and we leave further exploration for future work.


